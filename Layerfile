#This is an example webapp.io configuration for NodeJS
FROM vm/ubuntu:18.04
# To note: Layerfiles create VMs, *not* containers!

RUN apt-get update && \
    apt-get install apt-transport-https ca-certificates curl software-properties-common && \
    curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add - && \
    add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable" && \
    apt-get update && \
    apt install docker-ce python3 python3-pip awscli && \
    curl -sL https://deb.nodesource.com/setup_14.x | bash && \
    apt install -y nodejs && \
    rm -f /etc/apt/sources.list.d/nodesource.list

RUN mkdir /ms-playwright && mkdir /tmp/pw && cd /tmp/pw && npm init -y && npm i playwright && DEBIAN_FRONTEND=noninteractive npx playwright install-deps && rm -rf /tmp/pw && chmod -R 777 /ms-playwright

# install docker compose (easily starts required docker containers)
RUN curl -L "https://github.com/docker/compose/releases/download/1.26.2/docker-compose-$(uname -s)-$(uname -m)" \
    -o /usr/local/bin/docker-compose

RUN npm install -g yarn pm2
RUN apt install unzip

COPY . .

MEMORY 4G

SECRET ENV SCHEMA_OBJ_URL
RUN mkdir db && curl "$SCHEMA_OBJ_URL" > db/schema.sql

RUN yarn
RUN yarn setup:ee

BUILD ENV EXPOSE_WEBSITE_HOST

ENV LOGDNA_API_KEY=c7bdd500e3cfbfe457a2ec4168b8cfaa \
    DB_HOST=localhost \
    DB_USERNAME=root \
    DB_PASSWORD=password \
    DB_DATABASE=crusher \
    DB_PORT=3306 \
    MONGODB_CONNECTION_STRING=mongodb://localhost:27017/crusher \
    REDIS_HOST=localhost \
    REDIS_PORT=6379 \
    REDIS_PASSWORD= \
    STANDALONE_APP_URL=https://$EXPOSE_WEBSITE_HOST \
    NEXT_PUBLIC_INTERNAL_BACKEND_URL=https://$EXPOSE_WEBSITE_HOST/server \
    NEXT_PUBLIC_CRUSHER_MODE=enterprise

RUN NEXT_PUBLIC_INTERNAL_BACKEND_URL="$NEXT_PUBLIC_INTERNAL_BACKEND_URL" NODE_OPTIONS=--max-old-space-size=8096 sh scripts/build/build-all.sh

RUN sudo chmod +x /usr/local/bin/docker-compose
RUN cp ./.env.oss .env

# Start mysql, redis and mongo
RUN REPEATABLE STANDALONE_APP_URL="$STANDALONE_APP_URL" docker-compose -f docker/ee/docker-compose.yml  up --build -d --force-recreate

RUN node setup/dbMigration.js
RUN cp ./ecosystem.docker.js ecosystem.config.js


RUN BACKGROUND pm2 start --only "crusher-app,crusher-server,test-runner,video-processor"

EXPOSE WEBSITE http://localhost:3000

# To wait for server to starts

RUN BACKGROUND node scripts/waitTillCrusherLoaded.js --url="https://$EXPOSE_WEBSITE_HOST/server" && curl --location --request POST 'https://backend.crusher.dev/projects/258/tests/actions/run' \
    --header 'Content-Type: application/x-www-form-urlencoded' \
    --cookie "token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoyODIsInRlYW1faWQiOjIxOSwiaWF0IjoxNjMzNDkyOTc5LCJleHAiOjE2NjUwMjg5Nzl9.fftN81qi0yJEDs9HnqiW4tElDMWp4dTHnAofnABmZuE" \
    --data-urlencode 'githubRepoName=crusherdev/crusher' \
    --data-urlencode "host=https://$EXPOSE_WEBSITE_HOST" \
    --data-urlencode "githubCommitId=$GIT_COMMIT"
